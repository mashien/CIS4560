Here is the code to download the stock market dataset 
and how to process it with pigETL
---------------------------------------------------
##ssh to our class cluster##

$ ssh [yourusernamehere]@129.150.64.74

##wget below downloads our stock market data zip##

$ cd .. 

$ cd ..

$ cd ..

$ cd dev

$ cd shm

$ pwd

###NOTE: type "pwd" and it should say "dev/shm/" now you can proceed to the command below### 

$ wget --load-cookies /tmp/cookies.txt "https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1fr-FVU0ZddRNuYvmPo79Mpkj403BguOt' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\1\n/p')&id=1fr-FVU0ZddRNuYvmPo79Mpkj403BguOt" -O stock_data && rm -rf /tmp/cookies.txt

*********wait till download completes(takes approx 5 minutes)***************

$ ls

$ unzip stock_data

$ hdfs dfs -mkdir dataproj

***************the following "-put" statement will take ~20 minutes to complete*********************
$ hdfs dfs -put Tickers.xlsx dataproj/
$ hdfs dfs -put Data dataproj/
$ hdfs dfs -ls dataproj/

$ rm -r Data
$ rm -r stock_data
$ rm -r Tickers.xlsx

*************now you can process the data like we do from our labs******************

hdfs dfs -chmod 777 /user/mbarrio5/dataproj/Data/Data/*/*

*********************************************************************************************
code below only pulls 1 stock data 
***************************************************************************************
$ pig

$ stock_data = LOAD '/user/mbarrio5/dataproj/Data/Data/0002.HK/0002.HK.csv' USING PigStorage(',','-tagFile')
	AS (date:chararray, open:chararray, high:chararray,
	low:chararray, close:chararray, adjclose:chararray,
	volume:chararray);

$ Describe stock_data;

$ stock_data_subset = limit stock_data 50;

$ DUMP stock_data_subset;

*******************************************
$ stock_data = LOAD '/user/mbarrio5/dataproj/Data/Data/*/*' 
	USING PigStorage(',','-tagFile')
	AS (date:chararray, open:chararray, high:chararray,
	low:chararray, close:chararray, adjclose:chararray,
	volume:chararray);

$ stock_data_subset = stock_data;

$ store stock_data_subset into 'output/cmpldata' using PigStorage(',');

$ cd ..

$ cd ..

$ cd home

$ cd mbarrio5

$ hdfs dfs -get output/cmpldata/part-r-00000 testdata.csv

************Open a new git bash terminal*****************

$ scp mbarrio5@129.150.64.74:/home/mbarrio5/testdata.csv .

******************************for excel data cleaning, this is for the find and replace portion**********
CTRL + F
Example:
Find What = *L*
Replace With = United Kingdom

*.L*
United Kingdom
*.SW*
Switzerland
*.ST*
Sweden
*.MC*
Spain
*.KQ*
South Korea
*.OL*
Norway
*.AS*
Netherlands
*.TA*
Israel
*.JK*
Indonesia
*.NS*
India
*.BO*
India
*.AT*
Greece
*.DE*
Germany
*.MU*
Germany
*.BE*
Germany
*.PA*
France
*.F*
France
*.CO*
Denmark
*.SS*
China
*.TO*
Canada
*.V*
Canada
*.SA*
Brazil
*.BR*
Belgium
*.AX*
Australia
*.CSV*
United States





